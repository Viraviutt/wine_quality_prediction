import gradio as gr
import pandas as pd
import numpy as np
import mlflow.pyfunc
import os
from openai import OpenAI
from dotenv import load_dotenv

# Carga variables de entorno (para la clave de OpenAI)
load_dotenv()

# --- Configuraci贸n y Carga del Modelo ---

# Aseg煤rate de que este nombre coincida con el registrado en train.py
MODEL_NAME = "wine_quality_model" 
# Carga la versi贸n 'Production' del modelo registrado en MLflow
# NOTA: Debes tener el servidor de MLflow (mlflow ui) activo o haber configurado
# el tracking remoto para que esto funcione.
try:
    # Intenta cargar el modelo de 'Production'
    logged_model = f'models:/{MODEL_NAME}/Production'
    model = mlflow.pyfunc.load_model(logged_model)
    MODEL_STATUS = "Modelo Productivo (MLflow Registry)"
except Exception as e:
    # Fallback si MLflow no est谩 disponible o el modelo no est谩 en Production
    print(f"Error al cargar modelo de MLflow Registry: {e}")
    MODEL_STATUS = "Error al cargar modelo. Verifique MLflow UI."
    # Define un modelo dummy para que la app pueda iniciar
    class DummyModel:
        def predict(self, df):
            # Retorna una predicci贸n base si el modelo real falla
            return np.array([6.0])
    model = DummyModel()


# --- Configuraci贸n de la Interfaz ---

# Columnas de entrada para la predicci贸n
FEATURE_COLUMNS = [
    "fixed acidity", "volatile acidity", "citric acid", 
    "residual sugar", "chlorides", "free sulfur dioxide", 
    "total sulfur dioxide", "density", "pH", "sulphates", "alcohol"
]

# Valores iniciales de ejemplo (t铆picos de un vino blanco)
INITIAL_VALUES = {
    "fixed acidity": 7.0, 
    "volatile acidity": 0.27, 
    "citric acid": 0.36, 
    "residual sugar": 20.7, 
    "chlorides": 0.045, 
    "free sulfur dioxide": 45.0, 
    "total sulfur dioxide": 170.0, 
    "density": 1.001, 
    "pH": 3.0, 
    "sulphates": 0.45, 
    "alcohol": 8.8
}


# --- Funciones L贸gicas de Gradio ---

def get_gen_ai_explanation(input_data, prediction):
    """Genera una explicaci贸n Gen AI para la predicci贸n."""
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # Crear una descripci贸n concisa de las caracter铆sticas del vino
    characteristics = ", ".join([
        f"{col}: {val}" for col, val in zip(FEATURE_COLUMNS, input_data.iloc[0])
    ])
    
    prompt = f"""
    Un modelo de Machine Learning predijo que la calidad de un vino blanco es de {prediction[0]:.2f} (escala 0-10).
    Las propiedades fisicoqu铆micas del vino son: {characteristics}. 

    Genera una explicaci贸n de una sola frase (m谩x. 25 palabras) que justifique por qu茅 la calidad es alta, baja o media,
    bas谩ndote en las propiedades dadas. Enf贸cate en la relaci贸n entre alcohol/acidez/az煤car y calidad.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un sommelier experto en qu铆mica del vino y explicas predicciones de calidad."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=80
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"Error Gen AI: Verifique la API Key de OpenAI. {e}"


def predict_wine_quality(*args):
    """Funci贸n de predicci贸n que acepta los 11 argumentos de entrada."""
    
    # Crea el DataFrame de entrada con los 11 valores
    input_values = list(args)
    input_df = pd.DataFrame([input_values], columns=FEATURE_COLUMNS)
    
    # 1. Ejecutar la Predicci贸n
    prediction = model.predict(input_df)
    quality_score = prediction[0]

    # 2. Generar Explicaci贸n Gen AI
    explanation = get_gen_ai_explanation(input_df, prediction)
    
    # 3. Formatear la predicci贸n para mostrar
    formatted_prediction = f"Predicci贸n de Calidad: {quality_score:.2f} / 10"

    # 4. Determinar si el vino es "Bueno" o "Malo" para un insight adicional
    if quality_score >= 7.0:
        insight = "隆Excelente Predicci贸n! Probablemente un vino de alta calidad."
    elif quality_score >= 5.0:
        insight = "Calidad promedio. El modelo sugiere un vino bebible."
    else:
        insight = "Baja calidad. Se recomienda precauci贸n."
    
    # Retorna todos los outputs para los componentes de Gradio
    return formatted_prediction, insight, explanation


# --- Construcci贸n de la Interfaz Gradio ---

# Componentes de entrada din谩micos
input_components = []
for feature in FEATURE_COLUMNS:
    # Usar el valor inicial del diccionario
    default_value = INITIAL_VALUES.get(feature, 0.5) 
    input_components.append(
        gr.Number(
            label=f"{feature} (g/dm鲁 o valor correspondiente)", 
            value=default_value
        )
    )

# Componentes de salida
output_components = [
    gr.Textbox(label=" Resultado de la Predicci贸n", key="prediction_output"),
    gr.Textbox(label=" Insight de Calidad", key="insight_output"),
    gr.Textbox(label=" Explicaci贸n Gen AI (Sommelier Virtual)", key="genai_output")
]

# Interfaz principal
iface = gr.Interface(
    fn=predict_wine_quality,
    inputs=input_components,
    outputs=output_components,
    title=" Predicci贸n y Generaci贸n de Insights sobre Calidad de Vinos con MLOps",
    description=f"""
    Introduce las 11 propiedades fisicoqu铆micas del vino para predecir su calidad (escala 0-10).
    El modelo actual es la versi贸n **Production** cargada desde el **MLflow Model Registry** ({MODEL_STATUS}).
    La explicaci贸n textual se genera autom谩ticamente por un LLM (Gen AI) para interpretar el resultado.
    """,
    live=False,
    allow_flagging="never"
)

with gr.Blocks() as app:
    gr.Markdown("##  Predicci贸n y Generaci贸n de Insights sobre Calidad de Vinos con MLOps")
    

# Ejecutar la aplicaci贸n
if __name__ == "__main__":
    iface.launch(inbrowser=True, show_api=False)
